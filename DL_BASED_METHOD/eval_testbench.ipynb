{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aa9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "SEED = 0\n",
    "#------------------------------------------------------------------------------------\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "#------------------------------------------------------------------------------------\n",
    "def set_global_determinism(seed=SEED):\n",
    "    set_seeds(seed=seed)\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # Set this to -1 to run on CPU\n",
    "    \n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Call the above function with seed value\n",
    "set_global_determinism(seed=SEED)\n",
    "#-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f1f81b",
   "metadata": {},
   "source": [
    "### IMPORT THE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acefab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "from data_extraction import *\n",
    "from resp_signal_extraction import *\n",
    "from rr_extration import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import pickle as pkl\n",
    "from tf_model import *\n",
    "#from tf_model_evi import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "import evidential_deep_learning as edl\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from filters import *\n",
    "import plotly as py\n",
    "#import plotly.figure_factory as ff\n",
    "import ipywidgets as widgets\n",
    "import plotly.graph_objs as go\n",
    "#from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "#py.offline.init_notebook_mode(connected = True)\n",
    "#from plotly import tools\n",
    "import plotly.express as px\n",
    "import tensorflow_probability as tfp\n",
    "from keras import backend as K\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ec7b9",
   "metadata": {},
   "source": [
    "### SET THE CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16530820",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_conf = 'confe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672bd198",
   "metadata": {},
   "source": [
    "### CALL THE DATA FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output','rb') as f:\n",
    "    output_data = pkl.load(f)\n",
    "\n",
    "with open('input','rb') as f:\n",
    "    input_data = pkl.load(f)\n",
    "\n",
    "with open('raw_signal_2.pkl','rb') as f:\n",
    "    raw_data = pkl.load(f)\n",
    "\n",
    "#input_copy = input_data\n",
    "input_data = np.transpose(input_data, (0,2,1))\n",
    "raw_data = np.transpose(raw_data, (0,2,1))\n",
    "annotation = pd.read_pickle('/media/acrophase/pose1/charan/MultiRespDL/DL_BASED_METHOD/annotation.pkl')\n",
    "reference_rr = (annotation['Reference_RR'].values).reshape(-1,1)\n",
    "activity_id = (annotation['activity_id'].values).reshape(-1,1)\n",
    "\n",
    "input_data = np.around(input_data , decimals = 4)\n",
    "raw_data = np.around(raw_data , decimals = 4)\n",
    "output_data = np.around(output_data , decimals = 4)\n",
    "reference_rr = np.around(reference_rr , decimals = 4)\n",
    "\n",
    "tensor_input = tf.convert_to_tensor(input_data, dtype = 'float32')\n",
    "tensor_output = tf.convert_to_tensor(output_data, dtype = 'float32')\n",
    "tensor_ref_rr = tf.convert_to_tensor(reference_rr, dtype = 'float32')\n",
    "tensor_raw_data = tf.convert_to_tensor(raw_data, dtype = 'float32')\n",
    "\n",
    "training_ids = annotation['patient_id'] < 13\n",
    "\n",
    "x_train_data = tensor_input[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_data = tensor_input[tf.convert_to_tensor(~(training_ids.values))]\n",
    "x_train_ref_rr = tensor_ref_rr[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_ref_rr = tensor_ref_rr[tf.convert_to_tensor(~(training_ids.values))]\n",
    "x_train_raw_sig = tensor_raw_data[tf.convert_to_tensor(training_ids.values)]\n",
    "x_test_raw_sig = tensor_raw_data[tf.convert_to_tensor(~(training_ids.values))]\n",
    "\n",
    "y_train_data = tensor_output[tf.convert_to_tensor(training_ids.values)]\n",
    "y_test_data = tensor_output[tf.convert_to_tensor(~(training_ids.values))]\n",
    "\n",
    "train_activity_id = activity_id[training_ids.values]\n",
    "test_activity_id = activity_id[~(training_ids.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ba8bb",
   "metadata": {},
   "source": [
    "### SET THE TRAIN TEST DATASET FOR DIFFERENT CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aeb724",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confa':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_raw_sig)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "if input_conf == 'confb':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , y_train_data, x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , y_test_data, x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "                \n",
    "if input_conf == 'confc':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , y_train_data))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , y_test_data))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "        \n",
    "if input_conf == 'confd':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "        \n",
    "if input_conf == 'confe':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data , y_train_data, x_train_ref_rr))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_data)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data , y_test_data, x_test_ref_rr))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "        \n",
    "if input_conf == 'RespNet':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train_raw_sig , y_train_data))\n",
    "        train_dataset = train_dataset.shuffle(len(x_train_raw_sig)).batch(128)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test_raw_sig , y_test_data))\n",
    "        test_dataset = test_dataset.batch(128)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7596221",
   "metadata": {},
   "source": [
    "### TEST THE MODELS AND "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a0858",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confa':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/MultiRespDL/DL_BASED_METHOD/SAVED_MODELS/confa/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    start = time.time()\n",
    "    for step , (x_batch_test_raw, x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "    end = time.time()\n",
    "    model.summary()\n",
    "    print(end - start)\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw_multi(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/MultiRespDL/DL_BASED_METHOD/SAVED_MODELS/confb/best_model_100.h5')        \n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    start = time.time()\n",
    "    for step , (x_batch_test_raw , y_batch_test , x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr = model(x_batch_test_raw)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "    end = time.time()\n",
    "    model.summary()\n",
    "    print(end-start)\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confc':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/MultiRespDL/DL_BASED_METHOD/SAVED_MODELS/confc/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    start = time.time()\n",
    "    for step,(x_batch_test , y_batch_test) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = loss_fn(y_batch_test,output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "    end = time.time()\n",
    "    model.summary()\n",
    "    print(end-start)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confd':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Encoder(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/MultiRespDL/DL_BASED_METHOD/SAVED_MODELS/confd/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    start = time.time()\n",
    "    for step , (x_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test)\n",
    "        test_loss = loss_fn(x_batch_test_ref_rr , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "    end = time.time()\n",
    "    model.summary()\n",
    "    print(end - start)\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confe':\n",
    "    model_input_shape = (128,3)\n",
    "    model  = BRUnet_Multi_resp(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,128,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/MultiRespDL/DL_BASED_METHOD/SAVED_MODELS/confe/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    final_output_rr = tf.convert_to_tensor([])\n",
    "    start = time.time()\n",
    "    for step , (x_batch_test,y_batch_test,x_batch_test_ref_rr) in enumerate(test_dataset):\n",
    "        test_output,test_out_rr = model(x_batch_test)\n",
    "        test_loss_resp = loss_fn(y_batch_test  , test_output)\n",
    "        test_loss_rr = loss_fn(x_batch_test_ref_rr , test_out_rr)\n",
    "        test_loss = test_loss_resp + test_loss_rr\n",
    "        if step == 0:\n",
    "            final_output = test_output\n",
    "            final_output_rr = test_out_rr\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , test_output] , axis = 0)\n",
    "            final_output_rr = tf.concat([final_output_rr , test_out_rr] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "    end = time.time()\n",
    "    model.summary()\n",
    "    print(end-start)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'RespNet':\n",
    "    model_input_shape = (2048,3)\n",
    "    model  = BRUnet_raw(model_input_shape)\n",
    "    loss_fn = Huber()\n",
    "    model(tf.ones((128,2048,3)))\n",
    "    model.load_weights('/media/acrophase/pose1/charan/MultiRespDL/DL_BASED_METHOD/SAVED_MODELS/respnet/best_model_100.h5')\n",
    "    test_loss_list = []\n",
    "    final_output = tf.convert_to_tensor([])\n",
    "    start = time.time()\n",
    "    for step , (x_batch_test_raw,y_batch_test) in enumerate(test_dataset):\n",
    "        output = model(x_batch_test_raw)\n",
    "        test_loss = loss_fn(y_batch_test , output)\n",
    "        if step == 0:\n",
    "            final_output = output\n",
    "        else:\n",
    "            final_output = tf.concat([final_output , output] , axis = 0)\n",
    "        test_loss_list.append(test_loss)\n",
    "    end = time.time()\n",
    "    model.summary()\n",
    "    print(end - start)\n",
    "        \n",
    "#-------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaad490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremas_extraction(signal):\n",
    "    avg_breath_duration = np.array([])\n",
    "    extrema_relevent = []\n",
    "    for item in signal:\n",
    "        amplitude = np.array([])\n",
    "        pos_peaks , _ = scipy.signal.find_peaks(item , height = [-3000,3000])\n",
    "        neg_peaks , _ = scipy.signal.find_peaks(-1*item , height = [-3000 , 3000])\n",
    "        extremas = np.concatenate((pos_peaks , neg_peaks))\n",
    "        extremas = np.sort(extremas)\n",
    "        for i in range(len(extremas)):\n",
    "            amplitude = np.append(amplitude , item[int(extremas[i])])\n",
    "        amplitude_diff = np.abs(np.diff(amplitude))\n",
    "        q3 = np.percentile(amplitude_diff , 75)\n",
    "        threshold = 0.3*q3\n",
    "        eliminate_pairs_of_extrema = 1\n",
    "        while(eliminate_pairs_of_extrema):\n",
    "            amps = np.array([])\n",
    "            if len(extremas)<3:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                continue\n",
    "            for i in range(len(extremas)):\n",
    "                amps = np.append(amps , item[int(extremas[i])])\n",
    "            amp_diff = np.abs(np.diff(amps)) \n",
    "            min_amp_diff , index = min(amp_diff) , np.argmin(amp_diff)\n",
    "            #print(min_amp_diff)\n",
    "            if min_amp_diff > threshold:\n",
    "                eliminate_pairs_of_extrema = 0\n",
    "                #extrema_relevent = extremas\n",
    "            else:\n",
    "                extremas = np.concatenate((extremas[0:index] , extremas[index+2 :]))\n",
    "                #amplitude_diff = np.delete(amplitude_diff , index)\n",
    "        if item[int(extremas[0])] < item[int(extremas[1])]:\n",
    "            extremas = extremas[1:]\n",
    "        if item[int(extremas[-1])] < item[int(extremas[-2])]:\n",
    "            extremas = extremas[:-1]\n",
    "        no_of_breaths = (len(extremas)-1)/2\n",
    "        breath_duration = extremas[-1] - extremas[0]\n",
    "        avg_breath_duration = np.append(avg_breath_duration , breath_duration/no_of_breaths)\n",
    "        extrema_relevent.append(extremas)\n",
    "    return avg_breath_duration , extrema_relevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf5317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sig = y_test_data.numpy()\n",
    "fbpB , fbpA = band_pass(0.1,0.7,8)\n",
    "final_ref_resp_sig = []\n",
    "for item in ref_sig:\n",
    "    final_ref_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "final_ref_resp_sig = np.array(final_ref_resp_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confa':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "#----------------------------------------------------------------------------------------------------------------   \n",
    "if input_conf == 'confd':\n",
    "    final_output_rr = final_output.numpy()\n",
    "    final_output_rr = final_output_rr.reshape(final_output_rr.shape[0],final_output_rr.shape[1])\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    error = np.abs(avg_ref_breath - final_output_rr)\n",
    "    mae = np.mean(error)\n",
    "    rmse = np.sqrt(np.mean(error**2))\n",
    "    print('Mean Absolute Error for {} is: {}'.format(input_conf,mae))\n",
    "    print('Root Mean Square Error for {} is: {}'.format(input_conf,rmse))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a16d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Error for confb is: 2.3595224375361052\n",
    "#Root Mean Square Error for confb is: 2.962611863792384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confc':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "\n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------    \n",
    "if input_conf == 'RespNet':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_breaths = (60*4/duration_resp).reshape(-1,1)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - avg_breaths)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf == 'confe':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "if input_conf == 'confb':\n",
    "    final_output_resp_sig = []\n",
    "    inst_br_dur = []\n",
    "    inst_ref_br_dur = []\n",
    "    inst_rr = []\n",
    "    inst_ref_rr = []\n",
    "    \n",
    "    final_output_resp = final_output.numpy()\n",
    "    final_rr = final_output_rr.numpy()\n",
    "    final_output_resp = final_output_resp.reshape(final_output_resp.shape[0],final_output_resp.shape[1])\n",
    "    final_rr = final_rr.reshape(final_rr.shape[0],final_rr.shape[1])\n",
    "    for item in final_output_resp:\n",
    "        final_output_resp_sig.append(scipy.signal.filtfilt(fbpB,fbpA , item))\n",
    "        \n",
    "    final_output_resp_sig = np.array(final_output_resp_sig)\n",
    "    duration_resp,extremas_resp = extremas_extraction(final_output_resp_sig)\n",
    "    duration_ref_resp,extremas_ref_resp = extremas_extraction(final_ref_resp_sig)\n",
    "    avg_ref_breath = (60*4/duration_ref_resp).reshape(-1,1)\n",
    "    \n",
    "    error_avg_breaths = np.abs(avg_ref_breath - final_rr)\n",
    "    mae_avg_breath = np.mean(error_avg_breaths)\n",
    "    rmse_avg_breath = np.sqrt(np.mean(error_avg_breaths**2))\n",
    "    \n",
    "    for item in extremas_resp:\n",
    "        inst_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in extremas_ref_resp:\n",
    "        inst_ref_br_dur.append(np.diff(item[0::2]))\n",
    "    for item in inst_br_dur:\n",
    "        inst_rr.append(np.mean(60*4/item))\n",
    "    for item in inst_ref_br_dur:\n",
    "        inst_ref_rr.append(np.mean(60*4/item))\n",
    "    \n",
    "    inst_rr = (np.array(inst_rr)).reshape(-1,1)\n",
    "    inst_ref_rr = (np.array(inst_ref_rr)).reshape(-1,1)\n",
    "    \n",
    "    error_inst_breaths = np.abs(inst_ref_rr - inst_rr)\n",
    "    mae_inst_breath = np.mean(error_inst_breaths)\n",
    "    rmse_inst_breath = np.sqrt(np.mean(error_inst_breaths**2))\n",
    "    \n",
    "    print('Mean Absolute Error average wise for {} is: {}'.format(input_conf,mae_avg_breath))\n",
    "    print('Root Mean Square Error average wise for {} is: {}'.format(input_conf,rmse_avg_breath))\n",
    "    \n",
    "    print('Mean Absolute Error instantaneous wise for {} is: {}'.format(input_conf,mae_inst_breath))\n",
    "    print('Root Mean Square Error instantaneous wise for {} is: {}'.format(input_conf,rmse_inst_breath))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5eb020",
   "metadata": {},
   "outputs": [],
   "source": [
    "edr_hrv = [np.array([]) for i in range(len(x_test_data))]\n",
    "edr_rpeak = [np.array([]) for i in range(len(x_test_data))]\n",
    "adr = [np.array([]) for i in range(len(x_test_data))]\n",
    "for i in range(len(x_test_data)):\n",
    "    arr = np.transpose(x_test_data[i])\n",
    "    edr_hrv[i]=np.append(edr_hrv[i],arr[0])\n",
    "    edr_rpeak[i]=np.append(edr_rpeak[i],arr[1])\n",
    "    adr[i]=np.append(adr[i],arr[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f3ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_edr_hrv = []\n",
    "final_edr_rpeak = []\n",
    "final_adr = []\n",
    "for i in range(len(edr_hrv)):\n",
    "    final_edr_hrv.append(scipy.signal.filtfilt(fbpB,fbpA , edr_hrv[i]))\n",
    "    final_edr_rpeak.append(scipy.signal.filtfilt(fbpB,fbpA , edr_rpeak[i]))\n",
    "    final_adr.append(scipy.signal.filtfilt(fbpB,fbpA , adr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bfb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv_duration , _ = extremas_extraction(final_edr_hrv)\n",
    "rpeak_duration , _ = extremas_extraction(final_edr_rpeak)\n",
    "adr_duration , _ = extremas_extraction(final_adr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d63594",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_hrv = (60*4)/hrv_duration.reshape(-1,1)\n",
    "rr_rpeak = (60*4)/rpeak_duration.reshape(-1,1)\n",
    "rr_adr = (60*4)/adr_duration.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23186cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_hrv = np.abs(rr_hrv - avg_ref_breath)\n",
    "error_rpeak = np.abs(rr_rpeak - avg_ref_breath)\n",
    "error_adr = np.abs(rr_adr - avg_ref_breath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99170f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_hrv = np.mean(error_hrv)\n",
    "mae_rpeak = np.mean(error_rpeak)\n",
    "mae_adr = np.mean(error_adr)\n",
    "\n",
    "print(mae_hrv)\n",
    "print(mae_rpeak)\n",
    "print(mae_adr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f7eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf ==\"confc\" or input_conf == \"confb\" or input_conf == \"confe\" or input_conf == \"RespNet\":\n",
    "    error_modality = np.hstack((error_hrv , error_rpeak \n",
    "                      , error_adr, error_avg_breaths,error_inst_breaths))\n",
    "    col_modality = ['RRint' , 'Rpeak' , 'ADR' , 'Avg RR','Inst RR']\n",
    "    error_modality_df = pd.DataFrame(error_modality , columns = col_modality) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffae223",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if input_conf ==\"confc\" or input_conf == \"confb\" or input_conf == \"confe\" or input_conf == \"RespNet\":\n",
    "    plt.figure(1)\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "    boxplot = sns.boxplot(data = error_modality_df , showfliers = False , width = 0.5)\n",
    "    boxplot.set_xticklabels(boxplot.get_xticklabels(),rotation = 0,fontsize=15)\n",
    "    plt.ylabel('Absolute Error (BrPM)',fontsize=15)\n",
    "    #plt.grid(True,axis = 'y')\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.show()\n",
    "    #plt.savefig('modality_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf ==\"confc\" or input_conf == \"confb\" or input_conf == \"confe\" or input_conf == \"RespNet\":\n",
    "    array_hrv = np.concatenate((error_hrv, np.array([0 for i in range(len(error_hrv))]).reshape(-1,1),test_activity_id.reshape(-1,1)), axis = 1)\n",
    "    array_rpeak = np.concatenate((error_rpeak , np.array([1 for i in range(len(error_rpeak))]).reshape(-1,1),test_activity_id.reshape(-1,1)), axis = 1)\n",
    "    array_adr = np.concatenate((error_adr , np.array([2 for i in range(len(error_adr))]).reshape(-1,1),test_activity_id.reshape(-1,1)), axis = 1)\n",
    "    array_fusion = np.concatenate((error_inst_breaths , np.array([3 for i in range(len(error_inst_breaths))]).reshape(-1,1),test_activity_id.reshape(-1,1)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ffe795",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf ==\"confc\" or input_conf == \"confb\" or input_conf == \"confe\" or input_conf == \"RespNet\":\n",
    "    final_array = np.concatenate((array_hrv,array_rpeak,array_adr,array_fusion) , axis = 0)\n",
    "    data_frame = pd.DataFrame(final_array , columns = ['Absolute Error(BrPM)' , 'Modality' , 'Activity_id'])\n",
    "    data_frame['Modality'] = data_frame['Modality'].astype('category')\n",
    "    data_frame['Activity_id'] = data_frame['Activity_id'].astype('category')\n",
    "    data_frame['Modality'] = data_frame['Modality'].cat.rename_categories(['RRint' , 'Rpeak' , 'ADR' , 'Final RR'])\n",
    "    data_frame['Activity_id'] = data_frame['Activity_id'].cat.rename_categories(['Baseline' , 'Clean'+'\\n'+'baseline' , 'Cycling' , 'Driving','Lunch','No_activity',\n",
    "                                                      'Soccer','Stairs', 'Walking', 'Working'])\n",
    "    plt.figure(2)\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,11)\n",
    "    ax = sns.boxplot(x=\"Activity_id\", y=\"Absolute Error(BrPM)\", hue=\"Modality\", data=data_frame , showfliers = False,width = 0.8)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation = 0,fontsize=20)\n",
    "    plt.setp(ax.get_legend().get_title(), fontsize=18)\n",
    "    #ax.set_yticks([i for i in range(0, int(data_frame[\"Absolute Error(BrPM)\"].max()), 4)])\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize=16)\n",
    "    plt.xlabel('Activity',fontsize = 30)\n",
    "    plt.ylabel('Absolute Error(BrPM)',fontsize = 30)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.show()\n",
    "    plt.savefig('activity_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bland_altman_plot(predicted , truth):\n",
    "    '''\n",
    "    Inputs -- predicted -- Predicted Data\n",
    "              Truth -- Reference Data\n",
    "    Output -- None\n",
    "    Description -- Function gives the bland altman plot.\n",
    "    '''\n",
    "    predicted = np.asarray(predicted)\n",
    "    truth = np.asarray(truth)\n",
    "    mean_val = np.mean([predicted , truth] , axis=0)\n",
    "    diff = truth-predicted\n",
    "    mean_diff = np.mean(diff)\n",
    "    std_diff = np.std(diff , axis=0)\n",
    "    print(mean_diff)\n",
    "    print(mean_diff + 1.96*std_diff)\n",
    "    print(mean_diff - 1.96*std_diff)\n",
    "    plt.figure(3)\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "    plt.scatter(mean_val , diff,marker = 'o',facecolors='none',edgecolors='b')\n",
    "    plt.axhline(mean_diff , color = 'black' , linestyle = '-' , linewidth = 3)\n",
    "    plt.axhline(mean_diff + 1.96*std_diff , color = 'black' , linestyle = '--', linewidth = 3)\n",
    "    plt.axhline(mean_diff - 1.96*std_diff , color = 'black' , linestyle = '--', linewidth = 3)\n",
    "    plt.xlabel('Instantaneous RR(BrPM)' , size = 15)\n",
    "    plt.ylabel('RR_final - RR_ref(BrPM)' , size = 15)\n",
    "    plt.xticks(fontsize = 15)\n",
    "    plt.yticks(fontsize = 15)\n",
    "    plt.show()\n",
    "    #plt.savefig('bland_altman.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55812079",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf ==\"confc\" or input_conf == \"confb\" or input_conf == \"confe\" or input_conf == \"RespNet\":\n",
    "    bland_altman_plot(inst_rr,inst_ref_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76014436",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf ==\"confc\" or input_conf == \"confb\" or input_conf == \"confe\" or input_conf == \"RespNet\":\n",
    "    error_baseline = error_inst_breaths[np.where(test_activity_id == 0)]\n",
    "    error_stairs = error_inst_breaths[np.where(test_activity_id == 7)]\n",
    "    error_soccer = error_inst_breaths[np.where(test_activity_id == 6)]\n",
    "    error_cycling = error_inst_breaths[np.where(test_activity_id == 2)]\n",
    "    error_driving = error_inst_breaths[np.where(test_activity_id == 3)]\n",
    "    error_lunch = error_inst_breaths[np.where(test_activity_id == 4)]\n",
    "    error_walking = error_inst_breaths[np.where(test_activity_id == 8)]\n",
    "    error_working = error_inst_breaths[np.where(test_activity_id == 9)]\n",
    "\n",
    "    error_baseline_hrv = error_hrv[np.where(test_activity_id == 0)]\n",
    "    error_stairs_hrv = error_hrv[np.where(test_activity_id == 7)]\n",
    "    error_soccer_hrv = error_hrv[np.where(test_activity_id == 6)]\n",
    "    error_cycling_hrv = error_hrv[np.where(test_activity_id == 2)]\n",
    "    error_driving_hrv = error_hrv[np.where(test_activity_id == 3)]\n",
    "    error_lunch_hrv = error_hrv[np.where(test_activity_id == 4)]\n",
    "    error_walking_hrv = error_hrv[np.where(test_activity_id == 8)]\n",
    "    error_working_hrv = error_hrv[np.where(test_activity_id == 9)]\n",
    "\n",
    "    error_baseline_rpeak = error_rpeak[np.where(test_activity_id == 0)]\n",
    "    error_stairs_rpeak = error_rpeak[np.where(test_activity_id == 7)]\n",
    "    error_soccer_rpeak = error_rpeak[np.where(test_activity_id == 6)]\n",
    "    error_cycling_rpeak = error_rpeak[np.where(test_activity_id == 2)]\n",
    "    error_driving_rpeak = error_rpeak[np.where(test_activity_id == 3)]\n",
    "    error_lunch_rpeak = error_rpeak[np.where(test_activity_id == 4)]\n",
    "    error_walking_rpeak = error_rpeak[np.where(test_activity_id == 8)]\n",
    "    error_working_rpeak = error_rpeak[np.where(test_activity_id == 9)]\n",
    "\n",
    "    error_baseline_adr = error_adr[np.where(test_activity_id == 0)]\n",
    "    error_stairs_adr = error_adr[np.where(test_activity_id == 7)]\n",
    "    error_soccer_adr = error_adr[np.where(test_activity_id == 6)]\n",
    "    error_cycling_adr = error_adr[np.where(test_activity_id == 2)]\n",
    "    error_driving_adr = error_adr[np.where(test_activity_id == 3)]\n",
    "    error_lunch_adr = error_adr[np.where(test_activity_id == 4)]\n",
    "    error_walking_adr = error_adr[np.where(test_activity_id == 8)]\n",
    "    error_working_adr = error_adr[np.where(test_activity_id == 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f1d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_conf ==\"confc\" or input_conf == \"confb\" or input_conf == \"confe\" or input_conf == \"RespNet\":\n",
    "    print('stairs mean abs error hrv {}'.format(np.mean(np.abs(error_stairs_hrv))))\n",
    "    print('stairs mean abs error rpeak {}'.format(np.mean(np.abs(error_stairs_rpeak))))\n",
    "    print('stairs mean abs error adr {}'.format(np.mean(np.abs(error_stairs_adr))))\n",
    "    print('stairs mean abs error fusion {}'.format(np.mean(np.abs(error_stairs))))\n",
    "    print('-----------------------------------------------------------')\n",
    "    print('cycling mean abs error hrv {}'.format(np.mean(np.abs(error_cycling_hrv))))\n",
    "    print('cycling mean abs error rpeak {}'.format(np.mean(np.abs(error_cycling_rpeak))))\n",
    "    print('cycling mean abs error adr {}'.format(np.mean(np.abs(error_cycling_adr))))\n",
    "    print('cycling mean abs error fusion {}'.format(np.mean(np.abs(error_cycling))))\n",
    "    print('-----------------------------------------------------------')\n",
    "    print('walking mean abs error hrv {}'.format(np.mean(np.abs(error_walking_hrv))))\n",
    "    print('walking mean abs error rpeak {}'.format(np.mean(np.abs(error_walking_rpeak))))\n",
    "    print('walking mean abs error adr {}'.format(np.mean(np.abs(error_walking_adr))))\n",
    "    print('walking mean abs error fusion {}'.format(np.mean(np.abs(error_walking))))\n",
    "    print('-----------------------------------------------------------')\n",
    "    print('baseline mean abs error hrv {}'.format(np.mean(np.abs(error_baseline_hrv))))\n",
    "    print('baseline mean abs error rpeak {}'.format(np.mean(np.abs(error_baseline_rpeak))))\n",
    "    print('baseline mean abs error adr {}'.format(np.mean(np.abs(error_baseline_adr))))\n",
    "    print('baseline mean abs error fusion {}'.format(np.mean(np.abs(error_baseline))))\n",
    "    print('-----------------------------------------------------------')\n",
    "    print('Driving mean abs error hrv {}'.format(np.mean(np.abs(error_driving_hrv))))\n",
    "    print('Driving mean abs error rpeak {}'.format(np.mean(np.abs(error_driving_rpeak))))\n",
    "    print('Driving mean abs error adr {}'.format(np.mean(np.abs(error_driving_adr))))\n",
    "    print('Driving mean abs error fusion {}'.format(np.mean(np.abs(error_driving))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44209b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu25",
   "language": "python",
   "name": "tf_gpu25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
